global:
  # -- Enable for complete airgap environment
  airgap: false
  # -- By default aws sdk uses respective services endpoint urls but in case we want to provide custom those endpoint urls we can use following
  # -- Set global.awsServiceEndpointUrls.enabled to true if we want to enable custom endpoint urls
  # -- Set global.awsServiceEndpointUrls.endPointRegion.host to valid AWS region where this endpoint is available
  # -- Set global.awsServiceEndpointUrls.stsEndPointUrl to set sts endpoint url
  # -- Set global.awsServiceEndpointUrls.ecsEndPointUrl to set ecs endpoint url
  # -- Set global.awsServiceEndpointUrls.cloudwatchEndPointUrl to set cloud watch endpoint url
  awsServiceEndpointUrls:
    cloudwatchEndPointUrl: https://monitoring.us-east-2.amazonaws.com
    ecsEndPointUrl: https://ecs.us-east-2.amazonaws.com
    enabled: false
    endPointRegion: us-east-2
    stsEndPointUrl: https://sts.us-east-2.amazonaws.com
  # -- Add common annotations to all objects
  commonAnnotations: {}
  # -- Add common labels to all objects
  commonLabels: {}
  ti:
    # -- Enable to install ti service
    enabled: true
  cdc:
    # -- Enable to install Change data capture
    enabled: true
  ccm:
    # -- Enable to install Cloud Cloud Management
    enabled: false
  cd:
    # -- Enable to install CD
    enabled: true
  cg:
    enabled: false
  chaos:
    # -- Enable to install Chaos components(Beta)
    enabled: false
  ci:
    # -- Enable to install CI
    enabled: true
  # -- provide overrides to use in-cluster database or configure to use external databases
  database:
    clickhouse:
      enabled: false
    # -- settings to deploy mongo in-cluster or configure to use external mongo source
    mongo:
      # -- set additional arguments to mongo uri
      extraArgs: ""
      # --   set the mongo hosts if mongo.installed is set to false
      hosts: []
      # -- set false to configure external mongo and generate mongo uri protocol://hosts?extraArgs
      installed: true
      # -- provide the passwordKey to reference mongo password
      passwordKey: ""
      # -- set the protocol for mongo uri
      protocol: mongodb
      # -- provide the secretname to reference mongo username and password
      secretName: ""
      # -- provide the userKey to reference mongo username
      userKey: ""
    postgres:
      ## - extra arguments set to connection string
      extraArgs: ""
      ## - host array for external
      hosts:
        - <postgres ip>:5432
      ## - set this to false if you want to use external postgre cluster
      installed: true
      ## - key within secret containing password
      passwordKey: "password"
      ## - protocol to use for connection
      protocol: postgres
      ## - secret name containing external postgresql credentials
      secretName: "postgres-secret"
      ## - key within secret containing username
      userKey: "user"
    redis:
      # --  provide host name for redis
      hosts:
        - <internal-endpoint-with-port>
      ## - set this to false if you want to use external redis cluster
      installed: true
      ## - key within secret containing password
      passwordKey: "password"
      ## - secret name containing external redis credentials
      secretName: "redis-user-pass"
      ## - key within secret containing username
      userKey: "username"
    timescaledb:
      ## - key name within secret containing certificates
      certKey: "cert"
      ## - secret name containing timescaledb certificates
      certName: "tsdb-cert"
      # --  provide host name for timescaledb
      hosts:
        - hostname.timescale.com:5432
      ## - set this to false if you want to use external timescaledb cluster
      installed: true
      ## - key within secret containing password
      passwordKey: "password"
      ## - secret name containing external timescaledb credentials
      secretName: "tsdb-secret"
      ## - set this to true if you want to enabled external timescaledb ssl traffic
      sslEnabled: false
      ## - key within secret containing username
      userKey: "username"
  ff:
    # -- Enable to install  Feature Flags Component
    enabled: false
  ha: true
  # -- Global Docker image registry
  imageRegistry: ""
  ingress:
    annotations: {}
    className: "harness"
    # --- Enable Nginx ingress controller gateway
    enabled: false
    # -- add global.ingress.ingressGatewayServiceUrl in hosts if global.ingress.ingressGatewayServiceUrl is not empty.
    hosts:
      - 'my-host.example.org'
    # NOTE: for ip-based installs, either use sslip.io for an IP-encoded DNS name
    # OR set the hosts entry to '*'
    # -- set to ingress controller's k8s service FQDN for internal routing. eg "internal-nginx.default.svc.cluster.local"
    # If not set, internal request routing would happen via global.loadbalancerUrl
    ingressGatewayServiceUrl: ""
    objects:
      # -- annotations to be added to ingress Objects
      annotations: {}
    tls:
      enabled: false
      secretName: harness-cert
    useSelfSignedCert: false
  # --- Enable Istio Gateway
  istio:
    enabled: false
    gateway:
      # -- Enable to create istio-system gateway
      create: true
      # -- override the name of gateway
      name: ""
      # -- override the name of namespace to deploy gateway
      namespace: ""
      port: 443
      protocol: HTTPS
      # -- adds a gateway selector
      selector:
        istio: ingressgateway
    # -- add global.istio.istioGatewayServiceUrl in hosts if global.istio.istioGatewayServiceUrl is not empty.
    hosts:
      - '*'
    # -- set to istio gateway's k8s service FQDN for internal use case. eg "internal-istio-gateway.istio-system.svc.cluster.local"
    # If not set, internal request routing would happen via global.loadbalancerUrl
    istioGatewayServiceUrl: ""
    strict: false
    tls:
      credentialName:
      minProtocolVersion: TLSV1_2
      mode: SIMPLE
    virtualService:
      gateways:
        - ""
      # -- add global.istio.istioGatewayServiceUrl in hosts if global.istio.istioGatewayServiceUrl is not empty.
      hosts:
        - ""
  # -- set kubernetes version override, unrequired if installing using Helm.
  kubeVersion: ""
  license:
    # -- Insert CG License String to enable CG license
    cg: ''
    # -- Insert NG License String to enable NG license
    ng: ''
  # -- Fully qualified URL of your loadbalancer (ex: https://www.foo.com)
  loadbalancerURL: ""
  lwd:
    autocud:
      enabled: false
    enabled: false
  migrator:
    enabled: false
  mongoSSL: false
  ng:
    enabled: true
  ngcustomdashboard:
    # -- Enable to install  NG Custom Dashboards Component
    enabled: false
  servicediscoverymanager:
  # -- Enable to install Service Discovery Manager (Beta)
    enabled: false
  # -- Set global.proxy.enabled to true if we want calls aws sdk calls to organization, cur, ce, iam to go through proxy
  # -- Set global.proxy.host to proxy host or Ip(ex: localhost, 127.0.0.1)
  # -- Set global.proxy.port to proxy port, it takes integer value
  # -- Set global.proxy.username and global.proxy.password to proxy username and password, if not required remove it or keep blank
  # -- Set global.proxy.protocol to http or https depending on the proxy configuration
  proxy:
    enabled: false
    host: localhost
    password: ""
    port: 80
    protocol: http
    username: ""
  saml:
    # --  Enabled will not send invites to email and autoaccepts
    autoaccept: false
  smtpCreateSecret:
    # -- Enable to create SMTP secretFile
    enabled: false
  srm:
    # -- Enable to install SRM
    enabled: false
  ssca:
    # -- Enable to install Software Supply Chain Assurance (SSCA)
    enabled: false
  stackDriverLoggingEnabled: false
  sto:
    # -- Enable to install STO
    enabled: false
  # -- set storageClass for third party applications
  storageClass: ""
  storageClassName: ""
  # -- Set false to disable Immutable Delegate
  useImmutableDelegate: "true"
  # -- Set true to use delegate minimal image
  useMinimalDelegateImage: false
ccm:
  anomaly-detection:
    replicaCount: 2
  batch-processing:
    awsAccountTagsCollectionJobConfig:
      enabled: true
    # -- This proxy is used by S3 sync bucket aws cli command
    # -- Set ccm.batch-processing.cliProxy.enabled to true if we want calls aws sdk calls to organization, cur, ce, iam to go through proxy
    # -- Set ccm.batch-processing.cliProxy.host to proxy host or Ip(ex: localhost, 127.0.0.1)
    # -- Set ccm.batch-processing.cliProxy.port to proxy port, it takes integer value
    # -- Set ccm.batch-processing.cliProxy.username and ccm.batch-processing.cliProxy.password to proxy username and password, if not required remove it or keep blank
    # -- Set ccm.batch-processing.cliProxy.protocol to http or https depending on the proxy configuration
    cliProxy:
      enabled: false
      host: localhost
      password: ""
      port: 80
      protocol: http
      username: ""
    cloudProviderConfig:
      CLUSTER_DATA_GCS_BACKUP_BUCKET: "placeHolder"
      CLUSTER_DATA_GCS_BUCKET: "placeHolder"
      DATA_PIPELINE_CONFIG_GCS_BASE_PATH: "placeHolder"
      GCP_PROJECT_ID: "placeHolder"
      S3_SYNC_CONFIG_BUCKET_NAME: "placeHolder"
      S3_SYNC_CONFIG_REGION: "placeHolder"
    replicaCount: 2
    stackDriverLoggingEnabled: false
  ce-nextgen:
    cloudProviderConfig:
      GCP_PROJECT_ID: "placeHolder"
    stackDriverLoggingEnabled: false
  cloud-info:
    replicaCount: 2
  event-service:
    replicaCount: 2
  telescopes:
    replicaCount: 2
cd:
  gitops:
    autoscaling:
      enabled: false
    replicaCount: 2
chaos:
  chaos-common:
    installLinuxCRDs: false
  chaos-manager:
    autoscaling:
      enabled: true
      targetCPU: "80"
      targetMemory: "80"
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 600m
        memory: 512Mi
  chaos-web:
    autoscaling:
      enabled: true
      targetCPU: "80"
      targetMemory: "80"
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 500m
        memory: 512Mi
  chaos-k8s-ifs:
    autoscaling:
      enabled: true
      targetCPU: "80"
      targetMemory: "80"
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 500m
        memory: 512Mi 
  chaos-linux-ifc:
    autoscaling:
      enabled: true
      targetCPU: "80"
      targetMemory: "80"
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 500m
        memory: 512Mi 
  chaos-linux-ifs:
    autoscaling:
      enabled: true
      targetCPU: "80"
      targetMemory: "80"
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 500m
        memory: 512Mi
  chaos-machine-ifc:
    autoscaling:
      enabled: true
      targetCPU: "80"
      targetMemory: "80"
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 500m
        memory: 512Mi 
  chaos-machine-ifs:
    autoscaling:
      enabled: true
      targetCPU: "80"
      targetMemory: "80"
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 500m
        memory: 512Mi
ci:
  ci-manager:
    autoscaling:
      enabled: true
      minReplicas: 2
    java:
      memory: "4096m"
    resources:
      limits:
        memory: 6192Mi
      requests:
        cpu: 1
        memory: 6192Mi
  ti-service:
    autoscaling:
      enabled: true
      minReplicas: 2
    jobresources:
      limits:
        memory: 3072Mi
      requests:
        cpu: 1
        memory: 3072Mi
    resources:
      limits:
        memory: 3072Mi
      requests:
        cpu: 1
        memory: 3072Mi
## Platform Settings
platform:
  # -- Feature list to enable within platform.  Contact Harness for value
  access-control:
    appLogLevel: INFO
    autoscaling:
      enabled: true
      minReplicas: 2
    java:
      memory: 512m
    # -- set mongoHosts for external database hosts
    # -- mongoHosts:
    # -- - replica1.host.com:27017
    # -- - replica2.host.com:27017
    # -- - replica3.host.com:27017
    mongoHosts: []
    mongoSSL:
      enabled: false
    resources:
      limits:
        memory: 4096Mi
      requests:
        cpu: 1
        memory: 4096Mi
  bootstrap:
    database:
      clickhouse:
        enabled: false
      minio:
        defaultBuckets: "logs"
        fullnameOverride: "minio"
        mode: standalone
        affinity: {}
        nodeSelector: {}
        tolerations: []
        podAnnotations: {}
        persistence:
          size: 200Gi
      mongodb:
        arbiter:
          affinity: {}
          nodeSelector: {}
          tolerations: []
          annotations: {}
          podAnnotations: {}
        extraFlags:
          - "--wiredTigerCacheSizeGB=3"
        persistence:
          size: 200Gi
        replicaCount: 3
        resources:
          limits:
            memory: 8192Mi
          requests:
            cpu: 4
            memory: 8192Mi
      postgresql:
        primary:
          affinity: {}
          nodeSelector: {}
          tolerations: []
          podAnnotations: {}
          persistence:
            size: 200Gi
          resources:
            limits:
              memory: 8192Mi
            requests:
              cpu: 4
              memory: 8192Mi
      redis:
        affinity: {}
        nodeSelector: {}
        tolerations: []
        podAnnotations: {}
        redis:
          resources:
            limits:
              memory: 2048Mi
            requests:
              cpu: 1
              memory: 2048Mi
        replicaCount: 3
        sentinel:
          resources:
            limits:
              memory: 200Mi
            requests:
              cpu: 100m
              memory: 200Mi
        volumeClaimTemplate:
          resources:
            requests:
              storage: 10Gi
      timescaledb:
        affinity: {}
        nodeSelector: {}
        tolerations: []
        podAnnotations: {}
        autoscaling:
          enabled: false
        enabled: true
        replicaCount: 2
        # Increasing persistentVolumes size while upgrading a helm deployment
        # will fail because these values are immutable for a statefulset.
        # To increase the size, it requires to delete the statefulset
        # and then upgrade. For more information follow this document
        # https://developer.harness.io/docs/self-managed-enterprise-edition/advanced-configurations/increase-pv-size-statefulsets
        persistentVolumes:
          data:
            size: 100Gi
          wal:
            size: 1Gi
        resources:
          limits:
            memory: 2048Mi
          requests:
            cpu: 1
            memory: 2048Mi
    harness-secrets:
      enabled: true
    networking:
      defaultbackend:
        # -- Create will deploy a default backend into your cluster
        create: false
      nginx:
        affinity: {}
        controller:
          # -- annotations to be addded to ingress Controller
          annotations: {}
        # -- Create Nginx Controller.  True will deploy a controller into your cluster
        create: false
        healthNodePort: ""
        healthPort: ""
        httpNodePort: ""
        httpsNodePort: ""
        # -- docker image to be used
        loadBalancerEnabled: false
        loadBalancerIP: '0.0.0.0'
        nodeSelector: {}
        tolerations: []
  change-data-capture:
    appLogLevel: INFO
    autoscaling:
      enabled: false
      minReplicas: 2
    java:
      memory: 2048
    resources:
      limits:
        memory: 2880Mi
      requests:
        cpu: 1
        memory: 2880Mi
  delegate-proxy:
    autoscaling:
      enabled: false
    replicaCount: 2
    resources:
      limits:
        memory: 100Mi
      requests:
        cpu: 200m
        memory: 100Mi
  gateway:
    autoscaling:
      enabled: true
      minReplicas: 2
    java:
      memory: 2048
    resources:
      limits:
        memory: 3072Mi
      requests:
        cpu: 1
        memory: 3072Mi
  harness-manager:
    autoscaling:
      enabled: true
      minReplicas: 2
    external_graphql_rate_limit: "500"
    java:
      memory: "2048"
    resources:
      limits:
        memory: 3000Mi
      requests:
        cpu: 2
        memory: 3000Mi
  log-service:
    autoscaling:
      enabled: false
    replicaCount: 1
    resources:
      limits:
        memory: 3072Mi
      requests:
        cpu: 1
        memory: 3072Mi
  looker:
    config:
      # -- clickhouse database name
      clickhouseDatabase: 'ccm'
      # -- Leave empty if not deploying Clickhouse.
      # -- clickhouse hostname
      clickhouseHost: 'clickhouse'
      # -- clickhouse port
      clickhousePort: '8123'
      # -- clickhouse user
      clickhouseUser: 'default'
    ingress:
      hosts: []
      tls:
        secretName: ''
    resources:
      limits:
        memory: 12Gi
      requests:
        cpu: 2
        memory: 12Gi
    secrets:
      # -- Required: Looker license key
      lookerLicenseKey: ""
  migrator:
    autoscaling:
      enabled: true
      minReplicas: 2
    java:
      memory: "2048"
    resources:
      limits:
        memory: 3000Mi
      requests:
        cpu: 2
        memory: 3000Mi
  next-gen-ui:
    autoscaling:
      enabled: true
      minReplicas: 2
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 0.5
        memory: 512Mi
  ng-auth-ui:
    autoscaling:
      enabled: true
      minReplicas: 2
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 0.5
        memory: 512Mi
  ng-custom-dashboards:
    config:
      # -- Required: domain name of your looker instance, this must be accessible by users in your organisation
      lookerPubDomain: ''
      # -- Required: HTTP scheme used, either http or https
      lookerPubScheme: 'https'
    resources:
      limits:
        memory: 1Gi
      requests:
        cpu: 1
        memory: 500Mi
  ng-manager:
    autoscaling:
      enabled: true
      minReplicas: 2
    java:
      memory: "4096m"
    resources:
      limits:
        memory: 6144Mi
      requests:
        cpu: 2
        memory: 6144Mi
  pipeline-service:
    autoscaling:
      enabled: true
      minReplicas: 2
    java:
      memory: "4096m"
    resources:
      limits:
        memory: 6144Mi
      requests:
        cpu: 1
        memory: 6144Mi
  queue-service:
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 2
    resources:
      limits:
        memory: 250Mi
      requests:
        cpu: 100m
        memory: 250Mi
  platform-service:
    autoscaling:
      enabled: true
      minReplicas: 2
    java:
      memory: "3072m"
    resources:
      limits:
        memory: 4096Mi
      requests:
        cpu: 1
        memory: 4096Mi
  scm-service:
    autoscaling:
      enabled: false
    replicaCount: 2
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 0.1
        memory: 512Mi
  template-service:
    autoscaling:
      enabled: true
      minReplicas: 2
    java:
      memory: "2048m"
    resources:
      limits:
        memory: 3000Mi
      requests:
        cpu: 0.7
        memory: 3000Mi
  ui:
    autoscaling:
      enabled: true
      minReplicas: 2
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 0.5
        memory: 512Mi
srm:
  cv-nextgen:
    autoscaling:
      enabled: true
      minReplicas: 2
    java:
      memory: 2048
    resources:
      limits:
        memory: 3000Mi
      requests:
        cpu: 1
        memory: 3000Mi
  le-nextgen:
    autoscaling:
      enabled: true
      minReplicas: 2
    resources:
      limits:
        memory: 6132Mi
      requests:
        cpu: 4
        memory: 6132Mi
  learning-engine:
    autoscaling:
      enabled: true
      minReplicas: 2
    resources:
      limits:
        memory: 6132Mi
      requests:
        cpu: 4
        memory: 6132Mi
  verification-svc:
    autoscaling:
      enabled: true
      minReplicas: 2
    resources:
      limits:
        memory: 2048Mi
      requests:
        cpu: 1
        memory: 2048Mi
sto:
  sto-core:
    autoscaling:
      enabled: true
      minReplicas: 2
    resources:
      limits:
        memory: 500Mi
      requests:
        cpu: 500m
        memory: 500Mi
  sto-manager:
    autoscaling:
      enabled: true
      minReplicas: 2
    resources:
      limits:
        memory: 3072Mi
      requests:
        cpu: 1
        memory: 3072Mi
